{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0072eff8-4236-491c-a6bb-01ea5a8d501a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b47d6-9aaf-46a3-b9dc-01ceb09020dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b2e006-d84a-4fc6-9c8e-fc35f1ab1aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_path=\"/pscratch/sd/l/lemonboy/PDB70_training_ver_A/eigenvalue_training/saxs_r/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3f5271-fa34-4699-b023-ab60ea8b58fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test=os.path.join(training_path,'6LN0_A.pdb.pr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53efd692-9680-4a60-8644-29cca46b07ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>P(r)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.420565e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.758611e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>120.0</td>\n",
       "      <td>1.840159e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>120.5</td>\n",
       "      <td>7.102368e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>121.0</td>\n",
       "      <td>3.551184e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>121.5</td>\n",
       "      <td>6.456698e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>122.0</td>\n",
       "      <td>3.228349e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         r          P(r)\n",
       "0      0.0  0.000000e+00\n",
       "1      0.5  0.000000e+00\n",
       "2      1.0  0.000000e+00\n",
       "3      1.5  3.420565e-04\n",
       "4      2.0  1.758611e-04\n",
       "..     ...           ...\n",
       "240  120.0  1.840159e-07\n",
       "241  120.5  7.102368e-08\n",
       "242  121.0  3.551184e-08\n",
       "243  121.5  6.456698e-09\n",
       "244  122.0  3.228349e-09\n",
       "\n",
       "[245 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1319a2-547c-40f3-b7d9-9b67259d19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAXSDataset(Dataset):\n",
    "    def __init__(self, csv_list):\n",
    "        self.csv_list = csv_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv_list)\n",
    "    def __getitem__(self, idx):\n",
    "        data = pd.read_csv(self.csv_list[idx])\n",
    "        # The first point is always zero so I didn't include it into the dataset\n",
    "        features = torch.tensor(np.pad(data['P(r)'].values[1:], (0, 512-len(data['P(r)'].values[1:])),constant_values=(0,0)), dtype=torch.float32)\n",
    "        return features, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cee295-ea1d-411d-9acf-1afc06bd4b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "csv_list = glob.glob(training_path+'*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4052b48-5d6b-4e67-9fef-0771a3ac915c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#max_length=[]\n",
    "#for i in csv_list:\n",
    "    #pd_data=pd.read_csv(i)\n",
    "    #max_length.append(len(pd_data))\n",
    "    \n",
    "#print(max(max_length))\n",
    "#max_length.index(3179)\n",
    "#indices_of_largest_10 = sorted(range(len(max_length)), key=lambda i: max_length[i], reverse=True)[:10]\n",
    "#for i in indices_of_largest_10:\n",
    "    #print(max_length[i])\n",
    "#csv_list[42033]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a127b1c3-e25d-41d8-9b65-101dcb7feffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shuffle = True\n",
    "validation_split= 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d421b94e-4369-4185-bac9-7abd03d9963e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SAXSDataset(csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2d98ad-e246-4c04-824c-4a2baa27b87e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = len(dataset)\n",
    "num_validation_samples = int(validation_split * num_samples)\n",
    "num_train_samples = num_samples - num_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6375d892-858e-45d8-9a8f-3d548235bfce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [num_train_samples, num_validation_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0103f2-5639-47d0-a1c3-3cefab709058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52be911b-c4f7-465a-838e-446b41a80879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7efc386fb730>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e40e9d-13d9-4e8c-8934-5c1ba7d4f56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for batch_id, (data, target) in enumerate(train_dataloader):\n",
    "#    print(batch_id)\n",
    "#    print(\"datasize is %d\" % len(data))\n",
    "#    print(\"y size is %d\" % len(target))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e3b27-8467-4b64-a0ec-c9c7e24bfb1e",
   "metadata": {},
   "source": [
    "## VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "129fa37b-aee2-499b-8c38-153b10f428de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass VAE(nn.Module):\\n    # For P(r) the latent_size should be between 6-12. Longer sequence should have a larger\\n    # latent. For testing purpose we will set latent_size as 10\\n    \\n    def __init__(self,input_size=245, hidden_size=20, latent_size=10):\\n        super(VAE, self).__init__()\\n        self.input_size = input_size\\n        self.hidden_size = hidden_size\\n        self.latent_size = latent_size\\n        self.encoder_conv1 = nn.Conv1d(in_channels=1, out_channels=hidden_size,\\n                                      kernel_size=3, stride=1, padding=1)\\n        # The output should be 244,20\\n        self.encoder_avgpool = nn.AvgPool1d(kernal_size=4, stride=4)\\n        # The output shoule be 61,20\\n        self.encoder_fc_mu = nn.Linear(hidden_size, latent_size)\\n        self.encoder_fc_var = nn.Linear(hidden_size, latent_size)\\n        \\n        self.decoder_fc1 = nn.Linear(latent_size, hidden_size)\\n        self.decoder_fc2 = nn.Linear(hidden_size, input_size)\\n        \\n    def encode(self, x):\\n        x = F.relu(self.encoder_conv1(x.unsqueeze(1)))\\n        x = self.encoder_maxpool(x)\\n        mu = self.encoder_fc_mu(x)\\n        log_var self.encoder_fc_var(x)\\n    \\n    def decode(self, z):\\n        z = F.relu(self.decoder_fc1(z))\\n        return torch.sigmoid(self.decoder_fc2(z))\\n    \\n    def forward(self, x):\\n\\n        x_encoded = self.encoder(x)\\n        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\\n\\n        std = torch.exp(log_var / 2)\\n        q = torch.distributions.Normal(mu, std)\\n        z = q.rsample()\\n        \\n        x_hat = self.decoder(z)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class VAE(nn.Module):\n",
    "    # For P(r) the latent_size should be between 6-12. Longer sequence should have a larger\n",
    "    # latent. For testing purpose we will set latent_size as 10\n",
    "    \n",
    "    def __init__(self,input_size=245, hidden_size=20, latent_size=10):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_size = latent_size\n",
    "        self.encoder_conv1 = nn.Conv1d(in_channels=1, out_channels=hidden_size,\n",
    "                                      kernel_size=3, stride=1, padding=1)\n",
    "        # The output should be 244,20\n",
    "        self.encoder_avgpool = nn.AvgPool1d(kernal_size=4, stride=4)\n",
    "        # The output shoule be 61,20\n",
    "        self.encoder_fc_mu = nn.Linear(hidden_size, latent_size)\n",
    "        self.encoder_fc_var = nn.Linear(hidden_size, latent_size)\n",
    "        \n",
    "        self.decoder_fc1 = nn.Linear(latent_size, hidden_size)\n",
    "        self.decoder_fc2 = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.encoder_conv1(x.unsqueeze(1)))\n",
    "        x = self.encoder_maxpool(x)\n",
    "        mu = self.encoder_fc_mu(x)\n",
    "        log_var self.encoder_fc_var(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        z = F.relu(self.decoder_fc1(z))\n",
    "        return torch.sigmoid(self.decoder_fc2(z))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "        \n",
    "        x_hat = self.decoder(z)\n",
    "'''     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7552f65-4d42-4b14-8cdb-fa42a635e04e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89856c47-74a7-4bf3-b7ac-241a44818782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a5189a8-8b43-4a0b-8dbf-9a39a8a225e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa3dd511-4e4d-4c79-86b6-6b050398c425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "057e19cf-0fd8-4c53-a157-71d81e55a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAXS_to_Eigen(nn.Module):\n",
    "    def __init__(self, hidden_features, output_dim):\n",
    "        super().__init__()\n",
    "        self.channels=hidden_features\n",
    "        #self.upscale = nn.Linear(1,hidden_features)\n",
    "        self.q = nn.Linear(1, hidden_features)\n",
    "        self.k = nn.Linear(1, hidden_features)\n",
    "        self.v = nn.Linear(1, hidden_features)\n",
    "        self.out_layer = nn.Linear(hidden_features, output_dim)\n",
    "    def forward(self, x):\n",
    "        h_ = x[:, :, np.newaxis]\n",
    "        #print(x.shape, h_.shape)\n",
    "        #h_ = self.upscale(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "        w_ = torch.bmm(q,k.permute(0,2,1))\n",
    "        w_ = w_ * (self.channels**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_,dim=2)\n",
    "        h_ = torch.bmm(w_,v)\n",
    "        h_ = self.out_layer(h_)\n",
    "        h_ = nn.ReLU()(h_)\n",
    "        print(h_.shape)\n",
    "        return h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55e25837-6975-40f9-b922-63cffb2a6ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAXS_to_Eigen_Cov(nn.Module):\n",
    "    def __init__(self, hidden_features, output_dim):\n",
    "        super().__init__()\n",
    "        self.channels=hidden_features\n",
    "        self.q = nn.Conv1d(in_channels=1, out_channels=hidden_features, kernel_size=1)\n",
    "        self.k = nn.Conv1d(in_channels=1, out_channels=hidden_features, kernel_size=1)\n",
    "        self.v = nn.Conv1d(in_channels=1, out_channels=hidden_features, kernel_size=1)\n",
    "        self.out_layer = nn.Linear(hidden_features, output_dim)\n",
    "    def forward(self, x):\n",
    "        h_ = x[:, np.newaxis, :]\n",
    "        #print(x.shape, h_.shape)\n",
    "        #h_ = self.upscale(h_)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "        print(k.shape)\n",
    "        w_ = torch.bmm(q.permute(0,2,1),k)\n",
    "        w_ = w_ * (self.channels**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_,dim=2)\n",
    "        print(w_.shape)\n",
    "        print(v.shape)\n",
    "        h_ = torch.bmm(w_,v.permute(0,2,1))\n",
    "        \n",
    "        h_ = self.out_layer(h_)\n",
    "        h_ = nn.ReLU()(h_)\n",
    "        print(h_.shape)\n",
    "        return h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e23bc3e-8009-47b2-a673-dbf363fd8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross attention between sequence and p(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79d7dada-d229-429e-a48b-30f7b4e7743b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SAXS_to_Eigen_Cov(64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8f37ee6-e8f0-4358-a066-8f35d5ed205f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 512, 512])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 512, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         ...,\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235]],\n",
       "\n",
       "        [[0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         ...,\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235],\n",
       "         [0.1327, 0.3985, 0.5472,  ..., 0.1652, 0.0000, 0.4235]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3fff8-4baf-4e63-bfdc-1d7bb6c7fa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e1759fc-29f3-4239-a3c7-1b73b942610e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85b35460-3ae7-4876-8977-5e6f2e47b71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = SAXS_to_Eigen(64,128)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a16fbfc-438a-4562-b00d-ae9aebb6786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.0000e+00, 0.0000e+00, 6.4150e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.8886e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 5.0475e-07, 5.8927e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 7.2609e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.7945e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.3498e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]]) tensor([[0.0000e+00, 0.0000e+00, 6.4150e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.8886e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 5.0475e-07, 5.8927e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 7.2609e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 2.7945e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.3498e-04,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "for batch_id,(data,target) in enumerate(train_dataloader):\n",
    "    print(batch_id,data,target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2774dc9-9a1b-4af8-9f14-735d26cbe84d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3292, 0.0000]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46234388-5579-4819-8e55-bc97b58c4c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsize = len(train_dataloader.dataset)\\nmodel.train()\\nfor batch_id, (data, target) in enumerate(train_dataloader):\\n    pred = model(data)\\n    loss = loss_fn(pred, target)#Shift one digit\\n    \\n    loss.backward()\\n    optimizer.step()\\n    optimizer.zero_grad()\\n    \\n    print(f\\'Training Batch {batch_idx}: Data shape: {data.shape}, Target shape: {target.shape}\\')\\n    if batch % 100 == 0:\\n        loss, current = loss.item(), batch * batch_size + len(data)\\n        print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\" )\\n    if batch_id==1:\\n        break\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "size = len(train_dataloader.dataset)\n",
    "model.train()\n",
    "for batch_id, (data, target) in enumerate(train_dataloader):\n",
    "    pred = model(data)\n",
    "    loss = loss_fn(pred, target)#Shift one digit\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    print(f'Training Batch {batch_idx}: Data shape: {data.shape}, Target shape: {target.shape}')\n",
    "    if batch % 100 == 0:\n",
    "        loss, current = loss.item(), batch * batch_size + len(data)\n",
    "        print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\" )\n",
    "    if batch_id==1:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ec47a-d8e4-4a8d-b82e-d2024d8c7af5",
   "metadata": {},
   "source": [
    "## Pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a733b-d2a9-40de-b8a8-5033e45e4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAXSEncoderLightning(L.LightningModule):\n",
    "        def __init__(self, hidden_features ,output_dim):\n",
    "        super().__init__()\n",
    "        self.channels=hidden_features\n",
    "        self.q = nn.Linear(1, hidden_features)\n",
    "        self.k = nn.Linear(1, hidden_features)\n",
    "        self.v = nn.Linear(1, hidden_features)\n",
    "        self.out_layer = nn.Linear(hidden_features, output_dim)\n",
    "    def forward(self, x):\n",
    "        h_ = x[:, :, np.newaxis]\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "        w_ = torch.bmm(q,k.permute(0,2,1))\n",
    "        w_ = w_ * (self.channels**(-0.5))\n",
    "        w_ = torch.nn.functional.softmax(w_,dim=2)\n",
    "        h_ = torch.bmm(w_,v)\n",
    "        h_ = self.out_layer(h_)\n",
    "        h_ = nn.ReLU()(h_)\n",
    "        print(h_.shape)\n",
    "        return h_\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        loss = loss_fn(pred, target)\n",
    "        self.log(\"train_loss\",loss)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e86b32-97a1-46b3-a635-4cb495f7a5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alphaflow",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
